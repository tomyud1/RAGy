# RAGy - Modern RAG System

A powerful, user-friendly RAG (Retrieval-Augmented Generation) system that allows you to create, manage, and test multiple vector databases with different embedding models.

## ğŸ¯ Features

- **Multi-Project Support**: Create and manage multiple RAG projects
- **Flexible Document Processing**: Upload PDFs, DOCX, XLSX, TXT, MD, and more
- **Advanced Chunking**: Uses Docling for intelligent document chunking
- **Multiple Embedding Models**: Choose from MiniLM, BGE, and MPNet models
- **Real-time Progress**: WebSocket-based progress tracking
- **Vector DB Comparison**: Test and compare different embedding models
- **Modern UI**: Beautiful, grey-themed React interface
- **GPU Acceleration**: Leverages M3 Neural Engine for fast embeddings

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React Frontend    â”‚  â† Vite + React + Modern UI
â”‚   (Port 5173)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ HTTP/WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node.js/Express Backend (Port 3001)       â”‚
â”‚   - Project management                      â”‚
â”‚   - File upload (multer)                    â”‚
â”‚   - Chunking orchestration                  â”‚
â”‚   - Embedding generation (@xenova)          â”‚
â”‚   - Vector DB (hnswlib)                     â”‚
â”‚   - RAG queries                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚          â”‚
          â”‚    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚    â”‚ Python Service â”‚  â† Docling chunking
          â”‚    â”‚  (subprocess)  â”‚
          â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ Vector DBs â”‚  â† HNSW indices
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Installation

### Prerequisites

- Node.js 18+ and npm
- Python 3.9+
- macOS (for M3 Neural Engine) or Linux

### Setup

1. **Install Node dependencies:**

```bash
npm run setup
```

This will:
- Install Node.js dependencies
- Install Python dependencies (Docling, transformers, torch)

2. **Alternative manual setup:**

```bash
# Install Node packages
npm install

# Install Python packages
cd server/python
pip3 install -r requirements.txt
```

## ğŸš€ Usage

### Start Development Server

Run both frontend and backend:

```bash
npm run dev:all
```

Or run separately:

```bash
# Terminal 1 - Frontend
npm run dev

# Terminal 2 - Backend
npm run server
```

The application will be available at:
- Frontend: http://localhost:5173
- Backend API: http://localhost:3001

### Workflow

1. **Create a Project**
   - Click "Create New Project"
   - Enter a descriptive name (e.g., "Heat Transfer Textbook")

2. **Upload Documents**
   - Drag and drop your files
   - Supports: PDF, DOCX, XLSX, PPTX, TXT, MD, etc.
   - Files are stored in `data/projects/{project-id}/raw-files/`

3. **Choose Chunking Method**
   - Default: Docling Hybrid (recommended)
   - Or upload pre-chunked JSON files
   - Chunks preview available after processing

4. **Preview Chunks**
   - Review generated chunks
   - Check if context is preserved correctly
   - Use random sampling to inspect different sections
   - Approve when satisfied

5. **Select Embedding Model**
   - **MiniLM-L6-v2**: Fast, 384D (recommended for most)
   - **BGE-Base-v1.5**: High quality, 768D
   - **MPNet-Base-v2**: Balanced, 768D

6. **Generate Embeddings**
   - Real-time progress with WebSocket
   - Shows batch progress, speed, and ETA
   - GPU accelerated on M3 Macs
   - Creates vector database automatically

7. **Test RAG System**
   - Query your vector databases
   - Compare multiple models side-by-side
   - View similarity scores and results
   - Import external vector databases (coming soon)

## ğŸ“ Project Structure

```
RAGy/
â”œâ”€â”€ src/                          # React frontend
â”‚   â”œâ”€â”€ components/               # UI components
â”‚   â”‚   â”œâ”€â”€ steps/                # Wizard step components
â”‚   â”‚   â”‚   â”œâ”€â”€ FileUploadStep.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ChunkingMethodStep.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ChunkPreviewStep.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ EmbeddingModelStep.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ EmbeddingProgressStep.jsx
â”‚   â”‚   â”‚   â””â”€â”€ RAGTestingStep.jsx
â”‚   â”‚   â”œâ”€â”€ Header.jsx
â”‚   â”‚   â”œâ”€â”€ ProjectSelector.jsx
â”‚   â”‚   â”œâ”€â”€ ProjectWorkspace.jsx
â”‚   â”‚   â””â”€â”€ StepIndicator.jsx
â”‚   â”œâ”€â”€ App.jsx
â”‚   â”œâ”€â”€ main.jsx
â”‚   â””â”€â”€ index.css
â”œâ”€â”€ server/                       # Backend
â”‚   â”œâ”€â”€ services/                 # Business logic
â”‚   â”‚   â”œâ”€â”€ project.service.js
â”‚   â”‚   â”œâ”€â”€ chunking.service.js
â”‚   â”‚   â”œâ”€â”€ embedding.service.js
â”‚   â”‚   â””â”€â”€ rag.service.js
â”‚   â”œâ”€â”€ routes/                   # API routes
â”‚   â”‚   â”œâ”€â”€ project.routes.js
â”‚   â”‚   â”œâ”€â”€ upload.routes.js
â”‚   â”‚   â”œâ”€â”€ chunking.routes.js
â”‚   â”‚   â”œâ”€â”€ embedding.routes.js
â”‚   â”‚   â””â”€â”€ rag.routes.js
â”‚   â”œâ”€â”€ python/                   # Python services
â”‚   â”‚   â”œâ”€â”€ docling_chunker.py
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ server.js                 # Main server
â”œâ”€â”€ data/                         # Project data
â”‚   â””â”€â”€ projects/                 # User projects
â”‚       â””â”€â”€ {project-id}/
â”‚           â”œâ”€â”€ raw-files/        # Uploaded documents
â”‚           â”œâ”€â”€ chunked-data/     # Generated chunks
â”‚           â”œâ”€â”€ vector-dbs/       # Vector databases
â”‚           â””â”€â”€ project-config.json
â”œâ”€â”€ package.json
â”œâ”€â”€ vite.config.js
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

### Chunking Configuration

Modify in `ChunkingMethodStep.jsx`:

```javascript
config: {
  maxTokens: 512,      // Maximum tokens per chunk
  mergePeers: true     // Merge consecutive chunks with same headers
}
```

### Embedding Models

Add new models in `server/services/embedding.service.js`:

```javascript
const EMBEDDING_MODELS = {
  'model-id': {
    name: 'Xenova/model-name',
    dimensions: 384,
  },
};
```

## ğŸ› Troubleshooting

### Python Docling Issues

If chunking fails:

```bash
# Verify Python installation
python3 --version

# Reinstall Docling
cd server/python
pip3 install --upgrade -r requirements.txt

# Test manually
python3 docling_chunker.py <input_dir> <output_file>
```

### WebSocket Connection Issues

If progress updates don't show:

1. Check that backend is running on port 3001
2. Verify WebSocket endpoint: `ws://localhost:3001/ws`
3. Check browser console for errors

### File Upload Issues

Ensure you have write permissions:

```bash
chmod -R 755 data/
```

## ğŸ“ Example Use Cases

### 1. Student Learning Assistant

A student studying heat transfer can:
- Upload textbook PDFs, lecture notes, homework
- Create vector database with all materials
- Query specific concepts and get relevant context
- Compare different chunking strategies

### 2. Technical Documentation Search

Developer creating a searchable knowledge base:
- Upload API docs, tutorials, code examples
- Test different embedding models
- Find best model for their content type
- Export vector DB for production use

### 3. Research Paper Analysis

Researcher analyzing multiple papers:
- Upload collection of PDFs
- Chunk by sections/paragraphs
- Query across all papers
- Find related concepts and citations

## ğŸš§ Roadmap (Phase 2)

- [ ] AI Chat Integration (GPT-4, Claude)
- [ ] Custom chunking strategies
- [ ] Vector DB export/import
- [ ] User authentication & cloud sync
- [ ] Batch processing for large datasets
- [ ] Advanced filtering and metadata search
- [ ] Analytics and usage statistics

## ğŸ“ License

MIT

## ğŸ¤ Contributing

Contributions welcome! This is a powerful tool for students, researchers, and developers working with document-based AI applications.

---

Built with â¤ï¸ for the RAG community

